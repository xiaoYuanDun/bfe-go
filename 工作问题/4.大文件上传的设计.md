### 前端

- 后缀验证

- 文件分块

  - Blob 分块转 Buffer 数组
  - 通过 Buffer 构建 hash 标识（分块摘要）

- 预请求摘要列表

- 剔除无需上传的分块，已存在的文件分块不需要重复上传

- 使用可用 Buffer 构建 FormData 对象

- 控制并发数进行分块上传

### 后端

- 接收 hash 标识与文件实体，存储为零时文件

- 接受预请求是，从工作目录中寻找是否具有同名文件夹，文件夹中有哪些已存在的 hash 分块

---

### 演进

1. 前端验证 xlsx
2. 需求不变，但是文件变大后，难以满足需求
3. 校验功能转移至后端，但是整体上传文件变成新的性能瓶颈
4. 简单使用分块，并以 文件名 + idx 作为分块标识，大致可满足需求
5. 但是重传时，idx 不能作为唯一表示，文件修改后，idx 依然不变，可能会造成文件误拼接
6. 引入分块 hash 摘要，但是摘要运算比简单分块的性能低很多，页面卡顿依然存在，
7. 思考如何拆分 long task
   1. rIC 每次空闲执行一次摘要运算，需要控制分块大小，过大依然会出现短暂卡顿，请求不是性能瓶颈，可以尽量变成小块
   2. webworker，三方库引入困难
8. 最终使用 文件名 + 分块 hash 为每个片段命名
9. 加入并发控制
10. Promise.all 决议后，提交全量 hash 列表，给服务端分片拼接提供凭证

### 一些思考

- 关于 hash 标识的取值，这里是：文件名 + 分块 hash，每次做完文件分块之后，会得到最新的 hash 列表，用此列表去请求服务端临时文件夹中是否存在这些 hash，存在则不重复上传，同时这个列表也是后端拼接文件的关键标识。为什么 hash 命名是不使用 index 呢，

- 使用 rIC 重构摘要任务

- 创建写入流，用于新建合并文件，遍历所有分片文件，计算偏移量，为每个分片创建读取流，按照偏移量并发的写入写入流，最终生成文件

fs.readdir 读取所有文件
